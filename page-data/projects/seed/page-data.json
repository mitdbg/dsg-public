{"componentChunkName":"component---src-templates-project-js-content-file-path-src-markdowns-projects-seed-mdx","path":"/projects/seed/","result":{"data":{"mdx":{"frontmatter":{"title":"SEED: Domain-Specific Data Curation With Large Language Models","image":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","placeholder":{"fallback":"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAHCAIAAACHqfpvAAAACXBIWXMAAELmAABC5gGC1oevAAABU0lEQVR42i2Q226CQBCGef/XaJPSN7A2NumF2gtt4ikYpYAgC8uyZ1h28dTRdjIXk5n883/5vev1ervdGGPbXViW+HQ6WWsvl8vHaPQ+HLpHHZLk1ferqjqfz43WUfQTx1Hbtt6/mPPP6XR/15ez+Vxr/TYY+P4LDJTRMAyfn58QQuCBKxzHMWzg5BGMGaWUkCw5FAj11vXWaiFKhGhdM0JYzbSUgnPJuTPGdV1xzKE7cK7SVFFOalZTru/V9K4nRTEeT7LjcbNcTr6+ldbGGCFEhVDLuSLEdl3vnOekpAWOD3meoRLXIHbWgngbBJ0xwXo9my+VVFopYC7zvBFCUwq/IBqvBeYSFyWhVc24aI3p+75I02C12gVBGkV5mgG84hw+ZlGkwZky/WDxjJSKcS1Vo/RfO9MJQiDhJI436/VqsdjvdhXGKM8BW7BaCAoZNFL+Ag9UfeXKZIieAAAAAElFTkSuQmCC"},"images":{"fallback":{"src":"/static/7be1306421f2091a3ecf6303bd507394/f24b3/seed.png","srcSet":"/static/7be1306421f2091a3ecf6303bd507394/e5d28/seed.png 1124w,\n/static/7be1306421f2091a3ecf6303bd507394/df00b/seed.png 2248w,\n/static/7be1306421f2091a3ecf6303bd507394/f24b3/seed.png 4495w","sizes":"(min-width: 4495px) 4495px, 100vw"},"sources":[{"srcSet":"/static/7be1306421f2091a3ecf6303bd507394/69362/seed.avif 1124w,\n/static/7be1306421f2091a3ecf6303bd507394/bac75/seed.avif 2248w,\n/static/7be1306421f2091a3ecf6303bd507394/508b3/seed.avif 4495w","type":"image/avif","sizes":"(min-width: 4495px) 4495px, 100vw"},{"srcSet":"/static/7be1306421f2091a3ecf6303bd507394/9832c/seed.webp 1124w,\n/static/7be1306421f2091a3ecf6303bd507394/2bcfb/seed.webp 2248w,\n/static/7be1306421f2091a3ecf6303bd507394/295fb/seed.webp 4495w","type":"image/webp","sizes":"(min-width: 4495px) 4495px, 100vw"}]},"width":4495,"height":1547}}}}}},"pageContext":{"id":"a0135ca6-7292-5785-8762-54a3fa628c8a","frontmatter":{"title":"SEED: Domain-Specific Data Curation With Large Language Models","link":"/seed","summary":"We present SEED, an LLM-as-compiler approach that automatically generates domain-specific data curation solutions via Large Language Models (LLMs). Once the user describes a task, input data, and expected output, the SEED compiler produces a hybrid pipeline that combines LLM querying with more cost-effective alternatives, such as vector-based caching, LLM-generated code, and small models trained on LLM-annotated data. SEED features an optimizer that automatically selects from the four LLM-assisted modules and forms a hybrid execution pipeline that best fits the task at hand. In comparison to solutions that use the LLM on every data record, SEED achieves state-of-the-art or comparable few-shot performance, while significantly reducing the number of LLM calls.","status":"current","image":"../../images/projects/seed/seed.png"}}},"staticQueryHashes":["3649515864","465186600"],"slicesMap":{}}