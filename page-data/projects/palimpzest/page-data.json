{"componentChunkName":"component---src-templates-project-js-content-file-path-src-markdowns-projects-palimpzest-mdx","path":"/projects/palimpzest/","result":{"data":{"mdx":{"frontmatter":{"title":"A Declarative System for Optimizing AI Workloads","image":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","placeholder":{"fallback":"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAJCAYAAAAywQxIAAAACXBIWXMAAEzlAABM5QF1zvCVAAACvElEQVR42h2QTWjTcBjGc1GkTCp+MCeOsc2DzA2EIXoYDNwOgicP4nWCZ1HYBx5EBBGGH0cPwg5zU4eubuzDru2yrtvK2ib9yJJ/+pUstU2bdulSt7ZptiZ57Xwuz8sL74/neTGsIUfYcdMZcti/2acXppenlmccX5fwiOvHNopNJnOqse5HNedmWFvC/bUNImow2YooEKFFccMNxNwv1Web1aIO+1HGs17FplhoefbG1tLgnsWwFovVaj3XmE+Nj89fmVvxfBCLFQhx2XoguWtGdpCJ4knwxniFQQkvxQuwjZBOhkmTSSaB5lI17JPPYN875NcNyOn27tvNFoul5UZnZ+tJcu9v57CU3IVYIKDzOyEIEyQkaBqoNVcpijj/BsXCajxmCJ5FEBANKJrSsI+2zN1XX4LXGvfnrda2Rrqmi11dty6fAKkAOaJVKsAxtC5nRcjlsqZSlKEo5eQMn7LH6RAQcdYQfBuQikUhyvIa9l9t2BnsQqPyJazpxAcfDlpP1mQYjRyWNZDyJb2uG8DQCHwBErKSrAhC3qOUFECINVAsAX84Doo5UcNczJhjlR4Nr9JjhD3ylFxlRok19DKyQj9x+emFKZoTASV5UyjsAe50wIybBRenHUTDiSDiFXBHKFNRVSiGSZC2tzTssFrIHesVqNb+mhV1H2raARzrKphwXOL5xHxwKwgoxBgpNmYwFGXgfgZCfFEmk7znp58EcmHOkKU8yPk8pOJxDSur+/6yWspWa4epcqWUPjouc/W6Kmj1QyKb2f2+J+yClE6b+WweFKVkygUJquXyXiwaXCLWZmHLTRpisQaZxg8lFmnYvQf9V/v7e68PDPR19N7p6Rm439cxNPSotbu7vXlicqKPYrh3FM29JYLEc++mdxjH8RfLTvwxR4c+78URLNnduo2UQMwVQMqktX/kTgKnXqYddgAAAABJRU5ErkJggg=="},"images":{"fallback":{"src":"/static/5f24ebe58d00f19f73ebb98bd792261b/318d6/intro.png","srcSet":"/static/5f24ebe58d00f19f73ebb98bd792261b/185fa/intro.png 980w,\n/static/5f24ebe58d00f19f73ebb98bd792261b/1ef33/intro.png 1960w,\n/static/5f24ebe58d00f19f73ebb98bd792261b/318d6/intro.png 3920w","sizes":"(min-width: 3920px) 3920px, 100vw"},"sources":[{"srcSet":"/static/5f24ebe58d00f19f73ebb98bd792261b/8f7ca/intro.avif 980w,\n/static/5f24ebe58d00f19f73ebb98bd792261b/82554/intro.avif 1960w,\n/static/5f24ebe58d00f19f73ebb98bd792261b/6c79f/intro.avif 3920w","type":"image/avif","sizes":"(min-width: 3920px) 3920px, 100vw"},{"srcSet":"/static/5f24ebe58d00f19f73ebb98bd792261b/ca650/intro.webp 980w,\n/static/5f24ebe58d00f19f73ebb98bd792261b/9f962/intro.webp 1960w,\n/static/5f24ebe58d00f19f73ebb98bd792261b/a132f/intro.webp 3920w","type":"image/webp","sizes":"(min-width: 3920px) 3920px, 100vw"}]},"width":3920,"height":1810.0000000000002}}}}}},"pageContext":{"id":"1a55d3ca-2ed1-534a-acd5-25172f28bd9b","frontmatter":{"title":"A Declarative System for Optimizing AI Workloads","link":"/palimpzest","summary":"A long-standing goal of data management systems has been to build systems which can compute quantitative insights over large corpora of unstructured data in a cost-effective manner. Until recently, it was difficult and expensive to extract facts from company documents, data from scientific papers, or metrics from image and video corpora. Today's models can accomplish these tasks with high accuracy. However, a programmer who wants to answer a substantive AI-powered query must orchestrate large numbers of models, prompts, and data operations. For even a single query, the programmer has to make a vast number of decisions such as the choice of model, the right inference method, the most cost-effective inference hardware, the ideal prompt design, and so on. The optimal set of decisions can change as the query changes and as the rapidly-evolving technical landscape shifts. In this paper we present Palimpzest, a system that enables anyone to process AI-powered analytical queries simply by defining them in a declarative language. The system uses its cost optimization framework --- which explores the search space of AI models, prompting techniques, and related foundation model optimizations --- to implement the query plan with the best trade-offs between runtime, financial cost, and output data quality.  We describe the workload of AI-powered analytics tasks, the optimization methods that Palimpzest uses, and the prototype system itself. We evaluate Palimpzest on tasks in Legal Discovery, Real Estate Search, and Medical Schema Matching. We show that even our simple prototype offers a range of appealing plans, including one that is 3.3x faster and 2.9x cheaper than the baseline method, while also offering better data quality. With parallelism enabled, Palimpzest can produce plans with up to a 90.3x speedup at 9.1x lower cost relative to a single-threaded GPT-4 baseline, while obtaining an F1-score within 83.5% of the baseline. These require no additional work by the user.","status":"current","image":"../../images/projects/palimpzest/intro.png"}}},"staticQueryHashes":["3649515864","465186600"],"slicesMap":{}}