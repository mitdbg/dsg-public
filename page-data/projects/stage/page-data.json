{"componentChunkName":"component---src-templates-project-js-content-file-path-src-markdowns-projects-stage-mdx","path":"/projects/stage/","result":{"data":{"mdx":{"frontmatter":{"title":"Stage query execution time prediction","image":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","placeholder":{"fallback":"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAJCAYAAAAywQxIAAAACXBIWXMAAAsTAAALEwEAmpwYAAACG0lEQVR42k2SaW8aMRRF+f8/pGqrtkkUtbRE2SghYW0gDMzOLPYsMAMMZICUhFNX/VJL1nuS7aN773PFGdXQOp/IRIc8n9MzBa0nh/bIxY1yyrLEtKdMvYBktiDNCmbZgudyRygibMdF102yfEmUzKlMuifovc9s4nsiGXDz6FKt97hoDhjZEhklOK7HWBsrWMZ8sSCOE8amx9VQ8qMfcN6a0rcSgiCgMs9m+IFDkqYUxZokmeF6Ic40IE5nzPOFgsYEoVQQi7FSs1wVSKXGDmI8kRLEGVGasdttqejdIXbnCXsw4QgU2RJ/OMZ7GmN0H3FV/7J/YVtucR41Ju2eqiPE2GQ1y1hv9wqqwNGcbLmhEmlDOpenWO0WiYzQ+wPGl7c4zRZG/Q7t+ifWRMdTOcpuH7PRxLprItptcuXC8OdcNHSq9zaOyKlo+h017Z2y0iG8byt1I/aB4CAlByHZqN5tPmA99PgdSXVm4f0ymDTVIBRQV5C2tWTgrfHTQmUoQsJkim9Z/PW8VNksbJcyFDwHISvXp1gXrIoVhTslNzSGjSGN6pC5LylfDszWJcv1lvVGZRiHMa1Jixu/Trnacnh9JVaTNQ0LwzDx7YC+HKCtJuTqG6VqaPvtjqO69/b6xv/reDxSEUIgpUDEkqvrOu8/fFT1ltrFJadn53z9VuXLyRnV7zXcqUc6S4mThCiOiaJIvZUI8W8HQcgfSG6Jh+PDexIAAAAASUVORK5CYII="},"images":{"fallback":{"src":"/static/18f5ae06f823afac3e127f90073ebe3e/63a12/stage.png","srcSet":"/static/18f5ae06f823afac3e127f90073ebe3e/38e6f/stage.png 382w,\n/static/18f5ae06f823afac3e127f90073ebe3e/1708d/stage.png 764w,\n/static/18f5ae06f823afac3e127f90073ebe3e/63a12/stage.png 1528w","sizes":"(min-width: 1528px) 1528px, 100vw"},"sources":[{"srcSet":"/static/18f5ae06f823afac3e127f90073ebe3e/90ba1/stage.avif 382w,\n/static/18f5ae06f823afac3e127f90073ebe3e/03248/stage.avif 764w,\n/static/18f5ae06f823afac3e127f90073ebe3e/7a764/stage.avif 1528w","type":"image/avif","sizes":"(min-width: 1528px) 1528px, 100vw"},{"srcSet":"/static/18f5ae06f823afac3e127f90073ebe3e/d2a0a/stage.webp 382w,\n/static/18f5ae06f823afac3e127f90073ebe3e/320af/stage.webp 764w,\n/static/18f5ae06f823afac3e127f90073ebe3e/40669/stage.webp 1528w","type":"image/webp","sizes":"(min-width: 1528px) 1528px, 100vw"}]},"width":1528,"height":659}}}}}},"pageContext":{"id":"8d51021b-4c22-536b-b3e1-b71520da4d6d","frontmatter":{"title":"Stage query execution time prediction","link":"/stage","summary":"Query performance (e.g., execution time) prediction is a critical component of modern DBMSes. As a pioneering cloud data warehouse, Amazon Redshift relies on an accurate execution time prediction for many downstream tasks, ranging from high-level optimizations, such as automatically creating materialized views, to low-level tasks on the critical path of query execution, such as admission, scheduling, and execution resource control. Unfortunately, many existing execution time prediction techniques, including those used in Redshift, suffer from cold start issues, inaccurate estimation, and are not robust against workload/data changes. In this paper, we propose a novel hierarchical execution time predictor: the Stage predictor. The Stage predictor is designed to leverage the unique characteristics and challenges faced by Redshift. The Stage predictor consists of three model states: an execution time cache, a lightweight local model optimized for a specific DB instance with uncertainty measurement, and a complex global model that is transferable across all instances in Redshift. We design a systematic approach to use these models that best leverages optimality (cache), instance-optimization (local model), and transferable knowledge about Redshift (global model). Experimentally, we show that the Stage predictor makes more accurate and robust predictions while maintaining a practical inference latency and memory overhead. Overall, the Stage predictor can improve the average query execution latency by 20% on these instances compared to the prior query performance predictor in Redshift.","status":"current","image":"../../images/projects/stage/stage.png"}}},"staticQueryHashes":["3649515864","465186600"],"slicesMap":{}}